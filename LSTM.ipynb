{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_Agent():\n",
    "    \n",
    "    def __init__(self, keys):\n",
    "        self._initialize(keys)\n",
    "        \n",
    "    def _initialize(self, keys):\n",
    "        np.random.seed(0)\n",
    "        self.log_df = pd.DataFrame({key: [] for key in keys})\n",
    "        self.keys = self.log_df.columns\n",
    "        self.interesting = \",\".join(self.log_df.columns)\n",
    "        self.iter_count = 0     \n",
    "\n",
    "    def set_batch(self, n, feed_dict):\n",
    "        \n",
    "        keys = list(feed_dict.keys())\n",
    "        \n",
    "        data_n = len(feed_dict[keys[0]])\n",
    "        indices = np.random.choice(range(data_n), n, replace=False)\n",
    "        \n",
    "        feed_dict = {key: feed_dict[key][indices] for key in keys}\n",
    "        self.feed_dict = feed_dict\n",
    "    \n",
    "    def run_session(self, sess):\n",
    "        \n",
    "        values = sess.run(eval(self.interesting),\n",
    "                          feed_dict=self.feed_dict)\n",
    "        \n",
    "        self.recent_log = pd.Series(values, index=self.keys)\n",
    "        self.log_df = self.log_df.append([self.recent_log])\n",
    "        \n",
    "        self.iter_count += 1\n",
    "        \n",
    "    def trace(self, args, one_line_text=\"\"):\n",
    "        \n",
    "        iter_count = self.iter_count\n",
    "        deco = [\"-\", \"\\\\\", \"|\", \"/\"][iter_count%4]\n",
    "        \n",
    "        one_line_text = \"Iter: % 6d\"%iter_count\n",
    "        for arg in args:\n",
    "            one_line_text += \" %s %s: %0.9f\"%(\n",
    "                deco, arg, self.recent_log[arg]\n",
    "            )\n",
    "\n",
    "        sys.stdout.write(\"\\r%s\"%one_line_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_trian_X = pd.read_pickle(\"./data/normal_tr_X\")\n",
    "underscore_trian_X = pd.read_pickle(\"./data/underscore_tr_X\")\n",
    "train_y = pd.read_pickle(\"./data/tr_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_size = 64\n",
    "iter_n = 5000\n",
    "# cases = [\"normal\", \"underscore\"]\n",
    "cases = [\"normal\"]\n",
    "tfadic = {case: TF_Agent([\"loss\", \"learn\"]) for case in cases}\n",
    "\n",
    "for case in cases:\n",
    "    \n",
    "    if case == \"normal\":\n",
    "        train_X = normal_trian_X\n",
    "        squence_size = 80\n",
    "    elif case == \"underscore\":\n",
    "        train_X = underscore_trian_X\n",
    "        squence_size = 160\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    g = tf.get_default_graph()\n",
    "    tf.set_random_seed(1050554145)\n",
    "\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, squence_size, 128])\n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
    "\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=rnn_size)\n",
    "    outputs, state = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "    logits = state[1]\n",
    "\n",
    "    weight = tf.Variable(tf.truncated_normal([rnn_size, 2]))\n",
    "    bias = tf.Variable(tf.truncated_normal([2]))\n",
    "\n",
    "    fc = tf.matmul(logits, weight) + bias\n",
    "    loss = tf.losses.softmax_cross_entropy(y, fc)\n",
    "    learn = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "    initializer = tf.global_variables_initializer()\n",
    "\n",
    "    \n",
    "    sess = tf.Session(graph=g)\n",
    "    sess.run(initializer)\n",
    "\n",
    "    tfa = tfadic[case]\n",
    "    for _ in range(iter_n):\n",
    "        tfa.set_batch(32, {X: train_X, y: train_y})\n",
    "        tfa.run_session(sess)\n",
    "        tfa.trace([\"loss\"])\n",
    "\n",
    "    print()\n",
    "#     sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
