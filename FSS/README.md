## 순서

```bash
python crawler.py bank
python crawler.py sbank
python nlp.py
python model.py

# nlp와 model의 최종 파일을 csv로 추출
python csv.py
```


## CRAWLER

#### url에 들어가는 파라미터들을 설명합니다.
> 줄이 그어진 파라미터는 없어도 동작하는 것을 확인했으며, 스크립트에서 전송하지 않았습니다.
- ie=utf8
- where=news 
    > 네이버 포탈에서 뉴스 카테고리
- query=국민은행
    > 검색어
- ~~sm=tab_pge~~
    > 페이지 번호를 클릭해 유입되었음을 의미
- sort=1
    > 최신순으로 기사를 정렬
- ~~photo=0~~
    > 종류 상관 없이 모든 기사를 반환
- field=1
    > 제목에 검색어가 포함된 기사를 반환
- ~~reporter_article=~~
- ~~pd=3~~
- ~~ds=2000.01.01~~
    > 검색 시작 날짜
- ~~de=2017.12.31~~
    > 검색 종료 날짜
- ~~docid=~~
- nso=so:dd,p:from20000101to20171231,a:t
    > from 과 to 두 날짜 사이의 기사를 검색
- ~~mynews=0~~
- ~~cluster_rank=13~~
- start=11 
    > 반환된 기사들중 11번째 기사를 페이지의 첫번째 인덱스로
- ~~refresh_start: 0~~
    > 검색결과 자동고침 기능 해제

#### 추가적으로 쿼리에 이용할수 있는 문법들입니다. 
- & , 공백 = AND조건
    > 연산자 좌우의 둘 다 포함하는 문서 검색
- \+ = OR조건
    > 연산자 단어 둘 중 하나라도 포함하는 문서 검색
- ! = NOT조건
    > 연산자의 앞 단어는 나오고 뒷단어는 나오지 않는 문서 검색
- ~ = 인접연산자(순서무시)
    > 앞 단어와 뒷 단어가 순서에 관계없이 2단어 이내로 붙어 있는 문서 검색
- ^ = 인접연산자(순서고려)
    > 앞 단어와 뒷 단어가 순서대로 2단어 이내로 붙어 있는 문서 검색
- @() = 문장검색
    > 앞 단어와 뒷 단어가 한 문장 내에 존재하는 문서를 검색
- "" = 구문검색
    > 연산자 안의 구를 포함하는 문서 검색
- \* = 절단검색, 와일드 카드
    > 연산자 앞이나 뒤의 단어를 포함하는 문서 검색