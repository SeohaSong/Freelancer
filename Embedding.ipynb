{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_word22d(p, model):\n",
    "    \n",
    "    words = model.wv.index2word\n",
    "    pts = np.array([model.wv[word] for word in words])\n",
    "    T_pts = pts.T\n",
    "\n",
    "    p.scatter(T_pts[0], T_pts[1])\n",
    "    for i, word in enumerate(words):\n",
    "        p.annotate(word, pts[i])\n",
    "        \n",
    "    origin = [0, 0]\n",
    "    p.scatter(origin[0], origin[1], s=100)\n",
    "    p.annotate(\"ORIGIN\", origin, fontsize=14)\n",
    "    \n",
    "    mean_pt = pts.mean(axis=0)\n",
    "    p.scatter(mean_pt[0], mean_pt[1], s=100)\n",
    "    p.annotate(\"MEAN\", mean_pt, fontsize=14)\n",
    "    \n",
    "    if \"_\" in words:\n",
    "        kernel = model.wv[\"_\"]\n",
    "        p.scatter(kernel[0], kernel[1], c=\"red\", s=100)\n",
    "        p.annotate(\"UNDERSCORE\", kernel, fontsize=14)\n",
    "        \n",
    "    if \"UNKNOWN\" in words:\n",
    "        unknown = model.wv[\"UNKNOWN\"]\n",
    "        p.scatter(unknown[0], unknown[1], c=\"pink\", s=100)\n",
    "        p.annotate(\"UNKNOWN\", unknown, fontsize=14)\n",
    "        \n",
    "        \n",
    "def report_underscore(model1, model2):\n",
    "\n",
    "    plt.figure(figsize=[12, 6])\n",
    "\n",
    "    p1 = plt.axes([0, 0, 0.48, 0.96])\n",
    "    _plot_word22d(p1, model1)\n",
    "\n",
    "    p2 = plt.axes([0.54, 0, 0.48, 0.96])\n",
    "    _plot_word22d(p2, model2)\n",
    "\n",
    "    p3 = plt.axes([0, 0.98, 1, 0.04])\n",
    "    \n",
    "    word_n = len(model2.wv.index2word)\n",
    "    title = \"Number of words: %d\"%word_n\n",
    "    p3.text(0.4, 0, title, fontsize=20)\n",
    "    p3.set_axis_off()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_df(path):\n",
    "    df = pd.read_csv(path,\n",
    "                     encoding=\"ISO8859\",\n",
    "                     index_col=0)\n",
    "    df = df[df[\"label\"] != \"unsup\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    \n",
    "    def process(i, text):\n",
    "        text = re.sub(\"<br />\", \" \", text)\n",
    "        text = re.sub(\"[^A-Za-z0-9 .\\-']\", \"\", text)\n",
    "        text = re.sub(\"\\d+\", \"00\", text)\n",
    "        text = re.sub(\"-\", \" \", text)\n",
    "        text = re.sub(\"\\.\", \" \", text)\n",
    "        text = re.sub(\"\\s+\", \" \", text)\n",
    "        if i%100 == 0:\n",
    "            percent = i/data_n*100\n",
    "            sys.stdout.write(\"\\r% 5.2f%%\"%(percent))\n",
    "        return text.lower()\n",
    "    \n",
    "    data_n = len(df)\n",
    "    review_se = df[\"review\"]\n",
    "    \n",
    "    print(\"[load_data_df] Preprocessing data...\")\n",
    "    review_se = pd.Series(\n",
    "        [process(i, review)\n",
    "         for i, review in enumerate(review_se)]\n",
    "    )\n",
    "    sys.stdout.write(\"\\r% 5.2f%%\\n\"%(100))\n",
    "    \n",
    "    df[\"review\"] = review_se\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_freq(df):\n",
    "\n",
    "    data_n = len(df)\n",
    "    review_se = df[\"review\"]\n",
    "    freq=defaultdict(int)\n",
    "\n",
    "    print(\"[load_data_df] Calculating word frequency...\")\n",
    "    for i, sent in enumerate(review_se):\n",
    "        for word in sent.split():\n",
    "            freq[word] += 1\n",
    "        if i%100 == 0:\n",
    "            percent = i/data_n*100\n",
    "            sys.stdout.write(\"\\r% 5.2f%%\"%(percent))\n",
    "    sys.stdout.write(\"\\r% 5.2f%%\\n\"%(100))\n",
    "    \n",
    "    return freq\n",
    "\n",
    "def get_unknown_df(df, freq, min_count):\n",
    "    \n",
    "    def check8convert(sent):\n",
    "        text_list = [\n",
    "            \"UNKNOWN\" if freq[word] < min_count else word\n",
    "             for word in sent.split()\n",
    "        ]\n",
    "        return text_list\n",
    "    \n",
    "    df = df.copy()\n",
    "    df[\"review\"] = pd.Series([\n",
    "        check8convert(sent) for sent in df[\"review\"]\n",
    "    ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_normal_df(df):\n",
    "    df = df.copy()\n",
    "    df[\"review\"] = pd.Series([\n",
    "        [word for word in words if word != \"UNKNOWN\"]\n",
    "        for words in df[\"review\"]\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "def get_underscore_df(df):\n",
    "    df = df.copy()\n",
    "    df[\"review\"] = pd.Series([\n",
    "        (\"_ \"+\" _ \".join(words)+\" _\").split()\n",
    "        for words in df[\"review\"]\n",
    "    ])                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_data_df] Preprocessing data...\n",
      " 100.00%\n",
      "[load_data_df] Calculating word frequency...\n",
      " 100.00%\n"
     ]
    }
   ],
   "source": [
    "df = load_data_df(\"./data/master.csv\")\n",
    "df = preprocess(df)\n",
    "freq = get_freq(df)\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "unknown_df = get_unknown_df(df, freq, min_count)\n",
    "underscore_unknown_df = get_underscore_df(unknown_df)\n",
    "\n",
    "normal_df = get_normal_df(unknown_df)\n",
    "normal_df.to_pickle(\"./data/normal_df\")\n",
    "underscore_df = get_underscore_df(normal_df)\n",
    "underscore_df.to_pickle(\"./data/underscore_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "case_index = 1\n",
    "case = [\"report\", \"embedding\"][case_index]\n",
    "\n",
    "normal_window = 5\n",
    "underscore_window = normal_window*2\n",
    "workers = os.cpu_count()\n",
    "\n",
    "if case == \"report\":\n",
    "    size = 2\n",
    "    data_ns = [5, 10, 50, 100, 500, 1000]\n",
    "    experimental_df = unknown_df\n",
    "    control_df = underscore_unknown_df\n",
    "elif case == \"embedding\":\n",
    "    size = 128\n",
    "    data_ns = [len(normal_df)]\n",
    "    experimental_df = normal_df\n",
    "    control_df = underscore_df\n",
    "\n",
    "    \n",
    "for data_n in data_ns:    \n",
    "\n",
    "    model1 = Word2Vec(experimental_df[\"review\"][:data_n],\n",
    "                      size=size,\n",
    "                      window=normal_window,\n",
    "                      min_count=min_count,\n",
    "                      workers=workers,\n",
    "                    )\n",
    "\n",
    "    model2 = Word2Vec(control_df[\"review\"][:data_n],\n",
    "                      size=size,\n",
    "                      window=underscore_window,\n",
    "                      min_count=min_count,\n",
    "                      workers=workers)\n",
    "    \n",
    "    if case == \"report\":\n",
    "        report_underscore(model1, model2)\n",
    "    elif case == \"embedding\":\n",
    "        model1.save(\"./data/normal_model\")\n",
    "        model2.save(\"./data/underscore_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
