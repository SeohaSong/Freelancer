{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_df(min_count):\n",
    "\n",
    "    def preprocess(i, text):\n",
    "        text = re.sub(\"<br />\", \" \", text)\n",
    "        text = re.sub(\"[^A-Za-z0-9 .\\-']\", \"\", text)\n",
    "        text = re.sub(\"\\d+\", \"00\", text)\n",
    "        text = re.sub(\"-\", \" \", text)\n",
    "        text = re.sub(\"\\.\", \" \", text)\n",
    "        text = re.sub(\"\\s+\", \" \", text)\n",
    "        if i%100 == 0:\n",
    "            percent = i/data_n*100\n",
    "            sys.stdout.write(\"\\r% 5.2f%%\"%(percent))\n",
    "        return text.lower()\n",
    "    \n",
    "    def check8convert(i, text):\n",
    "        text_list = [\"UNKNOWN\" if freq[word] < min_count else word\n",
    "                     for word in text.split()]\n",
    "        if i%100 == 0:\n",
    "            percent = i/data_n*100\n",
    "            sys.stdout.write(\"\\r% 5.2f%%\"%(percent))\n",
    "        return \" \".join(text_list)\n",
    "    \n",
    "    df = pd.read_csv(\"./data/master.csv\",\n",
    "                     encoding=\"ISO8859\",\n",
    "                     index_col=0)\n",
    "    df = df.drop([\"file\"], axis=1)\n",
    "    data_n = len(df)\n",
    "    review_se = df[\"review\"]\n",
    "    freq=defaultdict(int)\n",
    "    \n",
    "    print(\"[load_data_df] Preprocessing data...\")\n",
    "    review_se = pd.Series(\n",
    "        [preprocess(i, review)\n",
    "         for i, review in enumerate(review_se)]\n",
    "    )\n",
    "    sys.stdout.write(\"\\r% 5.2f%%\\n\"%(100))\n",
    "    \n",
    "    print(\"[load_data_df] Calculating word frequency...\")\n",
    "    for i, sent in enumerate(review_se):\n",
    "        for word in sent.split():\n",
    "            freq[word] += 1\n",
    "        percent = i/data_n*100\n",
    "        sys.stdout.write(\"\\r% 5.2f%%\"%(percent))\n",
    "    sys.stdout.write(\"\\r% 5.2f%%\\n\"%(100))\n",
    "    \n",
    "    print(\"[load_data_df] Converting small-freq-word to 'UNKNOWN'...\")\n",
    "    review_se = pd.Series([check8convert(i, sent) for i, sent\n",
    "                           in enumerate(review_se)])                \n",
    "    sys.stdout.write(\"\\r% 5.2f%%\\n\"%(100))\n",
    "    \n",
    "    df[\"review\"] = review_se\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_toy_df(df, div_n, seed):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    tr_df = df[df[\"type\"] == \"train\"]\n",
    "    te_df = df[df[\"type\"] == \"test\"]\n",
    "\n",
    "    tr_n, te_n = len(tr_df)//div_n, len(te_df)//div_n\n",
    "    tr_idxs = np.random.choice(tr_df.index, tr_n, replace=False)\n",
    "    te_idxs = np.random.choice(te_df.index, te_n, replace=False)\n",
    "    \n",
    "    tr_df = tr_df.loc[tr_idxs]\n",
    "    te_df = te_df.loc[te_idxs]\n",
    "    df = pd.concat([te_df, tr_df])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def _plot_word22d(p, model):\n",
    "    \n",
    "    words = model.wv.index2word\n",
    "    pts = np.array([model.wv[word] for word in words])\n",
    "    T_pts = pts.T\n",
    "\n",
    "    p.scatter(T_pts[0], T_pts[1])\n",
    "    for i, word in enumerate(words):\n",
    "        p.annotate(word, pts[i])\n",
    "        \n",
    "    origin = [0, 0]\n",
    "    p.scatter(origin[0], origin[1], s=100)\n",
    "    p.annotate(\"ORIGIN\", origin, fontsize=14)\n",
    "    \n",
    "    mean_pt = pts.mean(axis=0)\n",
    "    p.scatter(mean_pt[0], mean_pt[1], s=100)\n",
    "    p.annotate(\"MEAN\", mean_pt, fontsize=14)\n",
    "    \n",
    "    if \"_\" in words:\n",
    "        kernel = model.wv[\"_\"]\n",
    "        p.scatter(kernel[0], kernel[1], c=\"red\", s=100)\n",
    "        p.annotate(\"UNDERSCORE\", kernel, fontsize=14)\n",
    "        \n",
    "    if \"UNKNOWN\" in words:\n",
    "        unknown = model.wv[\"UNKNOWN\"]\n",
    "        p.scatter(unknown[0], unknown[1], c=\"pink\", s=100)\n",
    "        p.annotate(\"UNKNOWN\", unknown, fontsize=14)\n",
    "        \n",
    "        \n",
    "def report_underscore(model1, model2, word_n):\n",
    "\n",
    "    plt.figure(figsize=[12, 6])\n",
    "\n",
    "    p1 = plt.axes([0, 0, 0.48, 0.96])\n",
    "    _plot_word22d(p1, model1)\n",
    "\n",
    "    p2 = plt.axes([0.54, 0, 0.48, 0.96])\n",
    "    _plot_word22d(p2, model2)\n",
    "\n",
    "    p3 = plt.axes([0, 0.98, 1, 0.04])\n",
    "    \n",
    "    title = \"Number of words: %d\"%word_n\n",
    "    p3.text(0.4, 0, title, fontsize=20)\n",
    "    p3.set_axis_off()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_data_df] Preprocessing data...\n",
      " 100.00%\n",
      "[load_data_df] Calculating word frequency...\n",
      " 100.00%\n",
      "[load_data_df] Converting small-freq-word to 'UNKNOWN'...\n",
      " 100.00%\n"
     ]
    }
   ],
   "source": [
    "min_count = 5\n",
    "df = load_data_df(min_count)\n",
    "\n",
    "size, window = 100, 10\n",
    "workers = os.cpu_count()\n",
    "\n",
    "div_n = 1\n",
    "toy_df = get_toy_df(df, div_n, 1050554145)\n",
    "sent_se = toy_df[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal    : 52.60772681236267\n",
      "Underscore: 71.93054366111755\n"
     ]
    }
   ],
   "source": [
    "sents = [sent.split() for sent in sent_se]\n",
    "start = time.time()\n",
    "model1 = Word2Vec(\n",
    "    sents, size=size, window=window, min_count=min_count, workers=workers\n",
    ")\n",
    "print(\"Normal    :\", time.time()-start)\n",
    "\n",
    "sents = [(\"_ \"+\" _ \".join(sent.split())+\" _\").split()\n",
    "         for sent in sent_se]\n",
    "start = time.time()\n",
    "model2 = Word2Vec(\n",
    "    sents, size=size, window=window, min_count=min_count, workers=workers\n",
    ")\n",
    "print(\"Underscore:\", time.time()-start)\n",
    "\n",
    "if div_n >= 1000:\n",
    "    report_underscore(model1, model2, len(model2.wv.index2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"./data/normal_wv\")\n",
    "model2.save(\"./data/underscore_wv\")\n",
    "pd.to_pickle(toy_df, \"./data/preprocessed_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
